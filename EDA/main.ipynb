{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The EDA of Physionet Data set regarding \"A Large Scale 12 Lead Electrocardiogram Database for Arrhythmia Study 1.0.0\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import os\n",
    "from scipy.signal import butter, filtfilt\n",
    "import biosppy.signals.ecg as ecg\n",
    "import psycopg2\n",
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Declaring Global variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'..\\a-large-scale-12-lead-electrocardiogram-database-for-arrhythmia-study-1.0.0\\WFDBRecords\\\\'\n",
    "count = 0\n",
    "lowcut = 0.66  # Lower cutoff frequency in Hz\n",
    "highcut = 46.0   # Higher cutoff frequency in Hz\n",
    "dbconn = None\n",
    "dbcur = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Visual each ECG Signal using wfdb function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(record):\n",
    "    _,axes = plt.subplots(12,1,figsize=(12,20))\n",
    "    leads = [\"I\", \"II\", \"III\", \"avR\", \"avF\", \"aVL\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]  \n",
    "    for i, lead in enumerate(leads):\n",
    "        axes[i].plot(record[:, i])\n",
    "        axes[i].set_ylabel(lead)       \n",
    "    plt.legend(leads)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Filtering Noise and Normalizing Signals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Butterworth bandpass filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    # Calculate the Nyquist frequency\n",
    "    nyquist_freq = 0.5 * fs\n",
    "    # Normalize the cutoff frequencies\n",
    "    low = lowcut / nyquist_freq\n",
    "    high = highcut / nyquist_freq\n",
    "    # Design the Butterworth bandpass filter\n",
    "    b, a = butter(order, [low, high], btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "# Apply the bandpass filter to the input data\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    # Design the Butterworth bandpass filter\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    # Filter the input data using the designed filter\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Calculating Heart Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_heartrate(record,fs):\n",
    "    ecg_signal = record[:,1]\n",
    "    # Process ECG signal to detect R-peaks\n",
    "    rpeaks = ecg.engzee_segmenter(ecg_signal, sampling_rate=500)[0]\n",
    "    # Calculate RR intervals (in seconds)\n",
    "    rr_intervals = np.diff(rpeaks) / fs\n",
    "    # Calculate Heart rate of Pateint\n",
    "    heart_rate = 60 * len(rr_intervals) / np.sum(rr_intervals)\n",
    "    return heart_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Calculating QRS Interval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_qrs_interval(record,fs):\n",
    "    ecg_signal = record[:,1]\n",
    "    # Process ECG signal to detect QRS complexes\n",
    "    qrs_indices = ecg.hamilton_segmenter(ecg_signal, sampling_rate=500)[0]\n",
    "\n",
    "    qrs_durations = []\n",
    "    for qrs_index in qrs_indices:\n",
    "        qrs_start = max(0, qrs_index - 0.05 * fs)\n",
    "        qrs_end = min(len(ecg_signal), qrs_index + 0.05 * fs)\n",
    "        qrs_duration = (qrs_end - qrs_start) / float(fs)\n",
    "        qrs_durations.append(qrs_duration)\n",
    "    avg_qrs_duration = np.mean(qrs_durations)\n",
    "    formatted_avg_qrs_duration = \"{:.3f}\".format(avg_qrs_duration)\n",
    "    return formatted_avg_qrs_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Applying Partial Principle Component Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pca_incremental(data_generator, batch_size=2000):\n",
    "    # Initialize Incremental PCA\n",
    "    ipca = IncrementalPCA(n_components=12)\n",
    "    # Process data in batches\n",
    "    for batch_data in data_generator(batch_size=batch_size):\n",
    "        print(len(batch_data))\n",
    "        total_data = np.empty((batch_size * 5000, 12))\n",
    "        for i, data_array in enumerate(batch_data):\n",
    "            start_index = i * 5000\n",
    "            end_index = start_index + 5000\n",
    "            total_data[start_index:end_index] = data_array\n",
    "        \n",
    "        centered_data = total_data - np.mean(total_data, axis=0)\n",
    "        \n",
    "        ipca.partial_fit(centered_data)\n",
    "        batch_data.clear()\n",
    "\n",
    "\n",
    "    # Get the principal components (eigenvectors)\n",
    "    principal_components = ipca.components_\n",
    "\n",
    "    # Get explained variance ratios\n",
    "    explained_variance = ipca.explained_variance_ratio_\n",
    "\n",
    "    # Plot explained variance for analysis (optional)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='-')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.title('Explained Variance by Principal Components')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    threshold = 0.9  # Example threshold: retain 90% of explained variance\n",
    "\n",
    "    explained_variance_sum = np.sum(explained_variance)\n",
    "    num_components = 0\n",
    "    for i in range(len(explained_variance)):\n",
    "        explained_variance_sum += explained_variance[i]\n",
    "        num_components = i + 1\n",
    "        if explained_variance_sum >= threshold:\n",
    "            break\n",
    "\n",
    "    print(f\"Number of components to retain for {threshold*100:.0f}% explained variance:\", num_components)\n",
    "\n",
    "    # Select the chosen number of principal components\n",
    "    selected_components = principal_components[:, :num_components]\n",
    "\n",
    "## Can Play Aroung witht Components or Can do futher processing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size=2000):\n",
    "\n",
    "    batch_data = []\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"EDA\",\n",
    "        user=\"postgres\",\n",
    "        password=\"admin\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Fetch data from the database in batches\n",
    "        offset = 0\n",
    "        while True:\n",
    "            # Fetch up to batch_size entries from the database\n",
    "            cur.execute(f\"SELECT n_signal FROM ECG LIMIT {batch_size} OFFSET {offset}\")\n",
    "            rows = cur.fetchall()\n",
    "            \n",
    "            if not rows:\n",
    "                break  # No more data to fetch\n",
    "            \n",
    "            # Convert fetched data to numpy array\n",
    "            for row in rows:\n",
    "                data = np.frombuffer(row[0],dtype=float).reshape(-1, 12)\n",
    "                # data = data.\n",
    "                \n",
    "                batch_data.append(data)\n",
    "\n",
    "            yield batch_data\n",
    "\n",
    "            # Move to the next batch\n",
    "            offset += batch_size\n",
    "\n",
    "    finally:\n",
    "        # Close database connection\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Insertion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Insertor():\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"EDA\",\n",
    "        user=\"postgres\",\n",
    "        password=\"admin\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        createQuery = '''CREATE TABLE IF NOT EXISTS ECG(\n",
    "                ID varchar(10) primary key,\n",
    "                AGE int,\n",
    "                GENDER varchar(10),\n",
    "                DX TEXT,\n",
    "                HR REAL,\n",
    "                p_signal BYTEA,\n",
    "                n_signal BYTEA)'''\n",
    "                \n",
    "                # QRS REAL,\n",
    "                # NGraph BYTEA,\n",
    "                # OGraph BYTEA,\n",
    "        cursor.execute(createQuery)\n",
    "            \n",
    "        for dir1 in os.listdir(dataset_path):\n",
    "            dir1_path = os.path.join(dataset_path, dir1)\n",
    "            \n",
    "            # Loop through the subdirectories\n",
    "            for dir2 in os.listdir(dir1_path):\n",
    "                dir2_path = os.path.join(dir1_path, dir2)\n",
    "\n",
    "                # Loop through the ECG records\n",
    "                for file_name in os.listdir(dir2_path):\n",
    "                    if file_name.endswith('.mat'):\n",
    "                        file_path = os.path.join(dir2_path, file_name[:-4])\n",
    "                        record = wfdb.rdrecord(file_path)\n",
    "                        \n",
    "                        write_to_db(conn, cursor, record)\n",
    "\n",
    "    \n",
    "    finally:\n",
    "        # Close database connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "def write_to_db(conn, cursor, record):\n",
    "\n",
    "    try:\n",
    "        age = int(record.comments[0][5:])\n",
    "    except:\n",
    "        age = 62\n",
    "                        \n",
    "    # o_plot_data = visualize_data(record.p_signal)\n",
    "    filtered_p_signal = np.zeros_like(record.p_signal)\n",
    "    for lead in range(12):\n",
    "        filtered_signal = bandpass_filter(record.p_signal[:, lead], lowcut, highcut, 500)\n",
    "        filtered_p_signal[:, lead] = filtered_signal\n",
    "                        \n",
    "    # n_plot_data = visualize_data(filtered_p_signal)\n",
    "                                                \n",
    "    insertValues = (record.record_name,\n",
    "                    age,\n",
    "                    record.comments[1][5:],\n",
    "                    record.comments[2][4:],\n",
    "                    calculate_heartrate(filtered_p_signal,record.fs),\n",
    "                    # calculate_qrs_interval(filtered_p_signal,record.fs),\n",
    "                    # psycopg2.Binary(n_plot_data),\n",
    "                    # psycopg2.Binary(o_plot_data),\n",
    "                    psycopg2.Binary(record.p_signal.tobytes()),\n",
    "                    psycopg2.Binary(filtered_p_signal.tobytes()))\n",
    "    cursor.execute('''INSERT INTO ECG (ID, AGE, GENDER,DX,HR,p_signal,n_signal) \n",
    "                   VALUES (%s,%s,%s,%s,%s,%s,%s)''',insertValues)\n",
    "    \n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Adding Diagnosis Count to DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alter_table():\n",
    "    conn = psycopg2.connect(\n",
    "        \n",
    "        dbname=\"EDA\",\n",
    "        user=\"postgres\",\n",
    "        password=\"admin\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"Alter Table ECG add column dxcount int\")\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "Alter_table() \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Saving Acronyns to DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import process_dx\n",
    "def write_acronym_to_db():\n",
    "# def write_pca_to_db(selected_components):\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        \n",
    "        dbname=\"EDA\",\n",
    "        user=\"postgres\",\n",
    "\n",
    "        password=\"admin\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"SELECT id,dx FROM ECG\")\n",
    "        dx  = cursor.fetchall()\n",
    "        for id,dxcode in dx:\n",
    "            cursor.execute(\"UPDATE ECG SET dxname= %s WHERE id = %s\", (process_dx(dxcode), id))\n",
    "            conn.commit() \n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close() \n",
    "        \n",
    "write_acronym_to_db()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Droping Columns to Push to CockRoachDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Database for this set is about 44 GB in size but Cockroach DB free teir only provide 10 GB, so I have to drop Columns or Two to Manage Size\n",
    "'''\n",
    "import psycopg2\n",
    "\n",
    "def drop_columns():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"EDA\",\n",
    "            user=\"postgres\",\n",
    "            password=\"admin\",\n",
    "            host=\"localhost\",\n",
    "            port=\"5432\"\n",
    "        )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Drop the columns dxname and acronym\n",
    "        cursor.execute(\"Alter Table ECG Drop Column n_signal, p_signal\")\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "        print(\"Columns dropped successfully.\")\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error while dropping columns:\", error)\n",
    "\n",
    "    finally:\n",
    "        if conn:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "\n",
    "drop_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Inserting Selected Coulmn to CockRoachDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Utils import process_dx\n",
    "import psycopg2\n",
    "\n",
    "os.environ[\"DATABASE_URL\"] = \"YOUR LINK HERE\"\n",
    "\n",
    "def write_to_db(cursor, record):\n",
    "    try:\n",
    "        age = int(record.comments[0][5:])\n",
    "    except:\n",
    "        age = 62\n",
    "                        \n",
    "    dxcode = record.comments[2][4:]\n",
    "    \n",
    "    # Check if ID already exists in the database\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM ECG WHERE ID = %s\", (record.record_name,))\n",
    "    result = cursor.fetchone()[0]\n",
    "\n",
    "    # If the ID doesn't exist, insert the record\n",
    "    if result == 0:\n",
    "        insertValues = (record.record_name,\n",
    "                        age,\n",
    "                        record.comments[1][5:],\n",
    "                        dxcode,\n",
    "                        calculate_heartrate(record.p_signal,record.fs),\n",
    "                        len(dxcode.split(',')),\n",
    "                        process_dx(dxcode)\n",
    "                        )\n",
    "        cursor.execute('''INSERT INTO ECG (ID, AGE, GENDER, DX, HR, dxcount, dxname) \n",
    "                        VALUES (%s,%s,%s,%s,%s,%s,%s)''', insertValues)\n",
    "        print(f\"Record '{record.record_name}' inserted into the database.\")\n",
    "    else:\n",
    "        print(f\"Record '{record.record_name}' already exists in the database. Skipping insertion.\")\n",
    "        \n",
    "\n",
    "# Establish database connection\n",
    "conn = psycopg2.connect(os.environ[\"DATABASE_URL\"])\n",
    "counter = 0 \n",
    "# Execute the insertion process\n",
    "cursor = conn.cursor()\n",
    "for dir1 in os.listdir(dataset_path):\n",
    "        dir1_path = os.path.join(dataset_path, dir1)\n",
    "        \n",
    "        # Loop through the subdirectories\n",
    "        for dir2 in os.listdir(dir1_path):\n",
    "            dir2_path = os.path.join(dir1_path, dir2)\n",
    "\n",
    "            # Loop through the ECG records\n",
    "            for file_name in os.listdir(dir2_path):\n",
    "                if file_name.endswith('.mat'):\n",
    "                    if counter > 10990:\n",
    "                            file_path = os.path.join(dir2_path, file_name[:-4])\n",
    "                            record = wfdb.rdrecord(file_path)\n",
    "                            write_to_db(cursor, record)\n",
    "                    counter+=1\n",
    "                    print(counter)\n",
    "        if counter > 10990:\n",
    "            conn.commit()\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deleting UnRequired Data Entries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "os.environ[\"DATABASE_URL\"] = \"Put YOUr LINK HERE\"\n",
    "\n",
    "def gender_deletor():\n",
    "\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(os.environ[\"DATABASE_URL\"])\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Fetch up to batch_size entries from the database\n",
    "        cur.execute(f\"SELECT id,gender FROM ECG\")\n",
    "        rows = cur.fetchall()\n",
    "        \n",
    "        # Convert fetched data to numpy array\n",
    "        for row in rows:\n",
    "            \n",
    "            # print(f\"{row[0]}: {row[1]}\")\n",
    "            if row[1] == \"Unknown\":\n",
    "                # with open(\"gender_deleted.txt\",\"a\") as f:\n",
    "                #     f.write(f\"{row[0]}\\n\")\n",
    "                cur.execute(f\"DELETE FROM ECG WHERE id = '{row[0]}'\")\n",
    "        conn.commit()\n",
    "\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "gender_deletor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "os.environ[\"DATABASE_URL\"] = \"Put YOUr LINK HERE\"\n",
    "\n",
    "def age_deletor():\n",
    "\n",
    "    conn = psycopg2.connect(os.environ[\"DATABASE_URL\"])\n",
    "    cur = conn.cursor()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Fetch up to batch_size entries from the database\n",
    "        cur.execute(f\"SELECT id,age FROM ECG\")\n",
    "        rows = cur.fetchall()\n",
    "        \n",
    "        # Convert fetched data to numpy array\n",
    "        for row in rows:\n",
    "            \n",
    "            # print(f\"{row[0]}: {row[1]}\")\n",
    "            if row[1] == 0:\n",
    "                with open(\"age_deleted.txt\",\"a\") as f:\n",
    "                    f.write(f\"{row[0]}\\n\")\n",
    "                # cur.execute(f\"DELETE FROM ECG WHERE id = '{row[0]}'\")\n",
    "                # conn.commit()\n",
    "\n",
    "    finally:\n",
    "        # Close database connection\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        \n",
    "age_deletor()\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_deletor(batch_size=2000):\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"EDA\",\n",
    "        user=\"postgres\",\n",
    "        password=\"admin\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Fetch data from the database in batches\n",
    "        offset = 0\n",
    "        while True:\n",
    "            # Fetch up to batch_size entries from the database\n",
    "            cur.execute(f\"SELECT id,p_signal FROM ECG LIMIT {batch_size} OFFSET {offset}\")\n",
    "            rows = cur.fetchall()\n",
    "            \n",
    "            if not rows:\n",
    "                break  # No more data to fetch\n",
    "            \n",
    "            # Convert fetched data to numpy array\n",
    "            for row in rows:\n",
    "                data = np.frombuffer(row[1],dtype=float)\n",
    "                data = data.reshape((5000,12))\n",
    "\n",
    "                print(f\"{row[0]}: {np.sum(np.isnan(data))}\")\n",
    "                if(np.sum(np.isnan(data)) > 0):\n",
    "                    with open(\"status.txt\",\"a\") as f:\n",
    "                        f.write(f\"{row[0]}: {np.sum(np.isnan(data))}\\n\")\n",
    "                    \n",
    "                    #delete from database\n",
    "                    \n",
    "                    # cur.execute(f\"DELETE FROM ECG WHERE id = '{row[0]}'\")\n",
    "                    # conn.commit()\n",
    "\n",
    "            # Move to the next batch\n",
    "            offset += batch_size\n",
    "\n",
    "    finally:\n",
    "        # Close database connection\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "signal_deletor(2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
