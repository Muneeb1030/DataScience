{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The EDA of Physionet Data set regarding \"A Large Scale 12 Lead Electrocardiogram Database for Arrhythmia Study 1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import os\n",
    "from scipy.signal import butter, filtfilt\n",
    "import biosppy.signals.ecg as ecg\n",
    "import psycopg2\n",
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'..\\a-large-scale-12-lead-electrocardiogram-database-for-arrhythmia-study-1.0.0\\WFDBRecords\\\\'\n",
    "count = 0\n",
    "# Adjusted cutoff frequencies for normalized signal values\n",
    "lowcut = 0.66  # Lower cutoff frequency in Hz\n",
    "highcut = 46.0   # Higher cutoff frequency in Hz\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual each ECG Signal from the provided dataset using wfdb function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(record,name):\n",
    "    _,axes = plt.subplots(12,1,figsize=(12,20))\n",
    "    \n",
    "    \n",
    "    leads = [\"I\", \"II\", \"III\", \"avR\", \"avF\", \"aVL\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "    \n",
    "    for i, lead in enumerate(leads):\n",
    "        axes[i].plot(record[:, i])\n",
    "        axes[i].set_ylabel(lead)\n",
    "        \n",
    "    plt.legend(leads)\n",
    "    plt.savefig(f'{name}{count}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for noise removal and signal normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyquist_freq = 0.5 * fs\n",
    "    low = lowcut / nyquist_freq\n",
    "    high = highcut / nyquist_freq\n",
    "    b, a = butter(order, [low, high], btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Heart rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_heartrate(record,fs):\n",
    "    ecg_signal = record[:,index]\n",
    "    # Process ECG signal to detect R-peaks\n",
    "    rpeaks = ecg.engzee_segmenter(ecg_signal, sampling_rate=500)[0]\n",
    "    # Calculate RR intervals (in seconds)\n",
    "    rr_intervals = np.diff(rpeaks) / fs  # Sampling rate is 500 Hz\n",
    "    # Calculate HRV metrics\n",
    "    # sdnn = np.std(rr_intervals)  # Standard deviation of NN intervals\n",
    "    # rmssd = np.sqrt(np.mean(np.diff(rr_intervals) ** 2))  # Root mean square of successive differences\n",
    "    heart_rate = 60 * len(rr_intervals) / np.sum(rr_intervals)\n",
    "\n",
    "    # Print HRV metrics\n",
    "    print(\"Heart rate:\", heart_rate)\n",
    "    # Print HRV metrics\n",
    "    # print(\"SDNN:\", sdnn)\n",
    "    # print(\"RMSSD:\", rmssd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating QRS Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_qrs_interval(record,fs):\n",
    "    ecg_signal = record[:,index]\n",
    "    # Process ECG signal to detect QRS complexes\n",
    "    qrs_indices = ecg.hamilton_segmenter(ecg_signal, sampling_rate=500)[0]\n",
    "\n",
    "    # Measure QRS duration for each QRS complex\n",
    "    qrs_durations = []\n",
    "    for qrs_index in qrs_indices:\n",
    "        # Define QRS complex boundaries (e.g., Â±50 ms around QRS peak)\n",
    "        qrs_start = max(0, qrs_index - 0.05 * fs)  # 50 ms before QRS peak\n",
    "        qrs_end = min(len(ecg_signal), qrs_index + 0.05 * fs)  # 50 ms after QRS peak\n",
    "        \n",
    "        # Calculate QRS duration (in seconds)\n",
    "        qrs_duration = (qrs_end - qrs_start) / float(fs)  # Sampling rate is 500 Hz\n",
    "        qrs_durations.append(qrs_duration)\n",
    "\n",
    "    # Calculate average QRS duration\n",
    "    avg_qrs_duration = np.mean(qrs_durations)# Format average QRS duration to display up to 3 decimal places\n",
    "    formatted_avg_qrs_duration = \"{:.3f}\".format(avg_qrs_duration)\n",
    "\n",
    "    print(\"Average QRS Duration:\", formatted_avg_qrs_duration, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Partial Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pca_incremental(data_generator, batch_size=1000):\n",
    "    # Initialize Incremental PCA\n",
    "    ipca = IncrementalPCA(n_components=2)\n",
    "\n",
    "    # Process data in batches\n",
    "    for batch_data in data_generator:\n",
    "        # Flatten the batch\n",
    "        flattened_data = batch_data.reshape((batch_data.shape[0], -1))\n",
    "        # Partial fit IPCA on the flattened batch\n",
    "        ipca.partial_fit(flattened_data)\n",
    "\n",
    "    # Get the principal components\n",
    "    pcs = ipca.components_\n",
    "\n",
    "    # Visualize the coefficients of the first two principal components\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, 60001), pcs[0], marker='o', linestyle='-')\n",
    "    plt.title('Coefficients of Principal Component 1')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Coefficient')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, 60001), pcs[1], marker='o', linestyle='-')\n",
    "    plt.title('Coefficients of Principal Component 2')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Coefficient')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print the explained variance ratio\n",
    "    print(\"Explained Variance Ratio:\")\n",
    "    print(ipca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size=1000):\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"EDA\",\n",
    "        user=\"postgres\",\n",
    "        password=\"admin\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Fetch data from the database in batches\n",
    "        offset = 0\n",
    "        while True:\n",
    "            # Fetch up to batch_size entries from the database\n",
    "            cursor.execute(f\"SELECT p_signal FROM ECG LIMIT {batch_size} OFFSET {offset}\")\n",
    "            rows = cursor.fetchall()\n",
    "            \n",
    "            if not rows:\n",
    "                break  # No more data to fetch\n",
    "            \n",
    "            # Convert fetched data to numpy array\n",
    "            batch_data = np.array([row[0] for row in rows])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            yield batch_data\n",
    "\n",
    "            # Move to the next batch\n",
    "            offset += batch_size\n",
    "\n",
    "    finally:\n",
    "        # Close database connection\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inserted into database from the data folder downloaded from physionet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Insertor():\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"EDA\",\n",
    "        user=\"postgres\",\n",
    "        password=\"admin\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    insertQuery = '''INSERT INTO ECG (ID, AGE, GENDER,DX,p_signal) VALUES (%s,%s,%s,%s,%s)'''\n",
    "    try:\n",
    "        createQuery = '''CREATE TABLE IF NOT EXISTS ECG(\n",
    "                ID varchar(10) primary key,\n",
    "                AGE int,\n",
    "                GENDER varchar(10),\n",
    "                DX TEXT,\n",
    "                p_signal BYTEA)'''\n",
    "        cursor.execute(createQuery)\n",
    "            \n",
    "        for dir1 in os.listdir(dataset_path):\n",
    "            dir1_path = os.path.join(dataset_path, dir1)\n",
    "            \n",
    "            # Loop through the subdirectories\n",
    "            for dir2 in os.listdir(dir1_path):\n",
    "                dir2_path = os.path.join(dir1_path, dir2)\n",
    "\n",
    "                # Loop through the ECG records\n",
    "                for file_name in os.listdir(dir2_path):\n",
    "                    if file_name.endswith('.mat'):\n",
    "                        file_path = os.path.join(dir2_path, file_name[:-4])\n",
    "                        record = wfdb.rdrecord(file_path)        \n",
    "                        try:\n",
    "                            age = int(record.comments[0][5:])\n",
    "                        except:\n",
    "                            age = 62\n",
    "                            \n",
    "                        insertValues = (record.record_name,age,record.comments[1][5:],record.comments[2][4:],psycopg2.Binary(record.p_signal.tobytes()))\n",
    "                        cursor.execute(insertQuery,insertValues)\n",
    "                        conn.commit()\n",
    "                        print(record.record_name)\n",
    "            \n",
    "    finally:\n",
    "        # Close database connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "data_Insertor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_Check():\n",
    "#     # Connect to the PostgreSQL database\n",
    "#     conn = psycopg2.connect(\n",
    "#         dbname=\"EDA\",\n",
    "#         user=\"postgres\",\n",
    "#         password=\"admin\",\n",
    "#         host=\"localhost\",\n",
    "#         port=\"5432\"\n",
    "#     )\n",
    "#     cursor = conn.cursor()\n",
    "    \n",
    "#     selectQuery = '''select p_signal from ecg where id = %s'''\n",
    "#     queryValues = ('JS00001',)\n",
    "#     try:\n",
    "#         cursor.execute(selectQuery,queryValues)\n",
    "#         array_binary = cursor.fetchone()[0]\n",
    "#         array = np.frombuffer(array_binary, dtype=float)  # Specify the dtype of the array\n",
    "#         array = array.reshape((5000,12)) \n",
    "#         conn.commit()\n",
    "#         print(array.shape)\n",
    "#         print(array)\n",
    "#     finally:\n",
    "        \n",
    "#         cursor.close()\n",
    "#         conn.close()\n",
    "        \n",
    "# data_Check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_signal = []\n",
    "record = None\n",
    "# Initialize an empty DataFrame to hold the final result\n",
    "final_df = None\n",
    "# Loop through the first-level directories\n",
    "for dir1 in os.listdir(dataset_path):\n",
    "    dir1_path = os.path.join(dataset_path, dir1)\n",
    "    \n",
    "    # Loop through the subdirectories\n",
    "    for dir2 in os.listdir(dir1_path):\n",
    "        dir2_path = os.path.join(dir1_path, dir2)\n",
    "\n",
    "        # Loop through the ECG records\n",
    "        for file_name in os.listdir(dir2_path):\n",
    "            if file_name.endswith('.mat'):\n",
    "                file_path = os.path.join(dir2_path, file_name[:-4])\n",
    "                count = count + 1\n",
    "                if count < 10000:\n",
    "                    record = wfdb.rdrecord(file_path)\n",
    "                    # print(record.__dict__)\n",
    "                    # visualize_data(record.p_signal, \"plot\")\n",
    "                    # Initialize filtered_p_signal array\n",
    "                    filtered_p_signal = np.zeros_like(record.p_signal)\n",
    "\n",
    "                    # Apply band-pass filter to each lead separately\n",
    "                    for lead in range(12):\n",
    "                        filtered_signal = bandpass_filter(record.p_signal[:, lead], lowcut, highcut, record.fs)\n",
    "                        filtered_p_signal[:, lead] = filtered_signal\n",
    "                    \n",
    "                    batch_signal.append(filtered_p_signal)\n",
    "                    print(np.array(batch_signal).shape)\n",
    "                    if len(batch_signal) == 1000:\n",
    "                        visualize_pca_incremental(np.array(batch_signal))\n",
    "                        batch_signal = []\n",
    "                    \n",
    "                    # visualize_pca(filtered_p_signal)\n",
    "                    # visualize_data(filtered_p_signal, \"Normailzed\")\n",
    "                    # calculate_heartrate(filtered_p_signal,record.fs)\n",
    "                    # calculate_qrs_interval(filtered_p_signal,record.fs)\n",
    "                else:\n",
    "                    \n",
    "                    break\n",
    "        # # Optionally, save the final DataFrame to a CSV file\n",
    "        # final_df.to_csv()\n",
    "        # final_df.drop(final_df.index, inplace=True)\n",
    "        # final_df=None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Block to have commented out code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _, singular_values, _ = np.linalg.svd(record.p_signal)\n",
    "    # print(np.count_nonzero(singular_values))\n",
    "    # print(record.p_signal.T.shape)\n",
    "    # print(np.linalg.matrix_rank(record.p_signal.T))\n",
    "    \n",
    "    # max(rank) = min(row, coulmns)\n",
    "    \n",
    "    # _, singular_values, _ = np.linalg.svd(record.p_signal.T)\n",
    "    # print(np.count_nonzero(singular_values))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Printing the data set attribute p_signal to get the idea of the signal of ecg\n",
    "    # print(record.record_name)\n",
    "    # print(record.p_signal.shape)\n",
    "    # print(type(record.p_signal))\n",
    "    # print(np.sum(np.isnan(record.p_signal) | (record.p_signal == None)))\n",
    "    # print(record.__dict__)\n",
    "    # wfdb.plot_wfdb(record)\n",
    "# visualize_ecg(dataset_path) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
